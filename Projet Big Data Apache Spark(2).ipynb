{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f3532250-894b-455b-b7a3-e783dc1f0c9d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Nom Etudiant : Diallo**  \n",
    "\n",
    "**Prenom Etudiant:Bineta**  \n",
    "\n",
    "**Classe :ING2GIT** \n",
    "\n",
    "**Date limite de dépot : 31/08/2022**\n",
    "\n",
    "\n",
    "# Travail à Faire:\n",
    "Télécharger le Datasets sur le lien Drive :  https://drive.google.com/file/d/1tuV0lyb2uWvOInodVTohpdCiAV5FrBX-/view?usp=sharing \n",
    "\n",
    "Repondre les questions ci-dessous avec le maximum de precisions et de détails.   \n",
    "Remplir `FILL_IN` avec les methodes qui correspondent à la réponse adéquate\n",
    "\n",
    "\n",
    "### Revenus des achats\n",
    "1. Extraire les revenus d'achat pour chaque événement\n",
    "2. Filtrer les événements dont le revenu n'est pas nul\n",
    "3. Vérifiez quels sont les types d'événements qui génèrent des revenus\n",
    "4. Supprimez la colonne inutile\n",
    "\n",
    "### Revenus par Traffic\n",
    "Obtenir les 3 sources de trafic générant le revenu total le plus élevé.\n",
    "5. Revenus cumulés par source de trafic\n",
    "7. Obtenir les 3 principales sources de trafic par revenu total\n",
    "6. Nettoyer les colonnes de revenus pour avoir deux décimales\n",
    "\n",
    "\n",
    "##### Methods\n",
    "- DataFrame: `select`, `drop`, `withColumn`, `filter`, `dropDuplicates`,  `groupBy`, `sort`, `limit`\n",
    "- Column: `isNotNull`, `alias`, `desc`, `cast`, `operators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "124f66d5-a758-40f9-9254-9802175a7eee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder.\n",
    "                        appName(\"Session de Rattrapage Big Data\").\n",
    "                        config(\"spark.ui.port\", \"0\").\n",
    "                        master(\"yarn\").\n",
    "                        getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e6a5343-3c8d-4b9b-9ea7-4b5897ff133b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val eventsPath = \"events.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54dcf1b1-4a15-48c7-a3bf-590499529d4a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val eventsDF = spark.read.json(eventsPath)\n",
    "eventsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ca867dd2-4e12-40ad-a63b-4300fe236849",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Extraire les revenus d'achat pour chaque événement\n",
    "Ajouter une nouvelle colonne **`revenue`** en faisant l'extration de **`ecommerce.purchase_revenue_in_usd`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4b6760a2-7b47-4713-aed3-65db8157dbe0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val revenue = eventsDF.select(\"ecommerce.purchase_revenue_in_usd\")\n",
    "revenue.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.col\n",
    "val revenueDF=eventsDF.withColumn(\"revenue\",col(\"ecommerce.purchase_revenue_in_usd\"))\n",
    "revenueDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0b36255e-809d-4f37-bf29-14a84fb54dbc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Filtrer les événements dont le revenu n'est pas null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c3ab4d8d-3ba9-4efe-a0b2-f64a313c52a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val purchasesDF = revenueDF.filter(\"revenue IS NOT NULL\")\n",
    "purchasesDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8c7799f6-4668-47fe-ad11-2d95fb42f3cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Vérifiez quels sont les types d'événements qui génèrent des revenus\n",
    "Trouvez des valeurs **`event_name`** uniques dans **`purchasesDF`**. Il y a deux façons de faire :\n",
    "- Sélectionnez \"event_name\" et recupérer les enregistrements distincts\n",
    "- Supprimez les enregistrements en double en fonction de \"event_name\" uniquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9be33ae8-08e1-4f11-901a-d11f94d1a2a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val distinctDF = purchasesDF.select(\"event_name\").distinct()\n",
    "distinctDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchasesDF.dropDuplicates(\"event_name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da232f23-514c-4423-975f-20162fec0cb9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Supprimez la colonne inutile\n",
    "Puisqu'il n'y a qu'un seul type d'événement, supprimez **`event_name`** de **`purchasesDF`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cff64c80-f082-408f-8ad2-50abd75d2f75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val cleanDF = purchasesDF.drop(\"event_name\")\n",
    "cleanDF.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c9ca35ef-7fa1-4259-b7cc-59a42a7e3fdc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Revenus cumulés par source de trafic\n",
    "- Grouper par **`traffic_source`**\n",
    "- Obtenir la somme de **`revenue`** comme **`total_rev`**\n",
    "- Obtenir la moyenne de **`revenue`** comme **`avg_rev`**\n",
    "\n",
    "N'oubliez pas d'importer toutes les fonctions intégrées nécessaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bd64d109-4513-48f9-b5b4-85f4ef6b1b0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val trafficDF1 = cleanDF.groupBy(\"traffic_source\").sum(\"revenue\")\n",
    "val trafficDFs=trafficDF1.withColumnRenamed(\"sum(revenue)\",\"total_rev\")\n",
    "trafficDFs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trafficDF2=cleanDF.groupBy(\"traffic_source\").avg(\"revenue\")\n",
    "val trafficDFss=trafficDF2.withColumnRenamed(\"avg(revenue)\",\"avg_rev\")\n",
    "trafficDFss.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "752ce304-d2e1-47f5-acd0-d5a30183bf19",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Obtenir les trois principales sources de trafic par revenu total\n",
    "- Trier par **`total_rev`** dans l'ordre décroissant\n",
    "- Se limiter aux trois premières lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "89de0a73-924d-4b55-8ed2-9b936dabc496",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "import org.Apache.spark.sql.functions._\n",
    "val topTrafficDFs = trafficDFs.sort(desc(\"total_rev\"))\n",
    "topTrafficDFs.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val topTrafficDFss = trafficDFss.sort(desc(\"avg_rev\"))\n",
    "topTrafficDFss.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e46516b0-0637-47c4-a29d-58b32c8760db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Limitez les colonnes de revenus à deux décimales pointés\n",
    "- Modifier les colonnes **`avg_rev`** et **`total_rev`** pour les convertir en des nombres avec deux décimales pointés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9660408e-252d-4b78-a6e6-e3028640f4b0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%scala\n",
    "val finalDFs = topTrafficDFs.withColumn(\"total_rev\", col(\"total_rev\").cast(\"Decimal(10,2)\"))\n",
    "finalDFs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val finalDFss = topTrafficDFss.withColumn(\"avg_rev\", col(\"avg_rev\").cast(\"Decimal(10,2)\"))\n",
    "finalDFss.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Examen Rattrapage  Big Data ISI",
   "notebookOrigID": 2952678889524244,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
